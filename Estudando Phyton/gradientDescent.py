import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


def gradientDescent():
    s = pd.Series([1, 3, 5, np.nan, 6, 8])

    t0 = 0
    t1 = 0
    t2 = 0
    t3 = 0
    s = pd.Series([t1, t2, t3]);

    f2 = t0 + t1*x;
    f = t0 + s*x;



    return
